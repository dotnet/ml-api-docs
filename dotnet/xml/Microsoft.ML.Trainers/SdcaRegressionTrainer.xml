<Type Name="SdcaRegressionTrainer" FullName="Microsoft.ML.Trainers.SdcaRegressionTrainer">
  <TypeSignature Language="C#" Value="public sealed class SdcaRegressionTrainer : Microsoft.ML.Trainers.SdcaTrainerBase&lt;Microsoft.ML.Trainers.SdcaRegressionTrainer.Options,Microsoft.ML.Data.RegressionPredictionTransformer&lt;Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;,Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit SdcaRegressionTrainer extends Microsoft.ML.Trainers.SdcaTrainerBase`3&lt;class Microsoft.ML.Trainers.SdcaRegressionTrainer/Options, class Microsoft.ML.Data.RegressionPredictionTransformer`1&lt;class Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;, class Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Trainers.SdcaRegressionTrainer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class SdcaRegressionTrainer&#xA;Inherits SdcaTrainerBase(Of SdcaRegressionTrainer.Options, RegressionPredictionTransformer(Of LinearRegressionModelParameters), LinearRegressionModelParameters)" />
  <TypeSignature Language="F#" Value="type SdcaRegressionTrainer = class&#xA;    inherit SdcaTrainerBase&lt;SdcaRegressionTrainer.Options, RegressionPredictionTransformer&lt;LinearRegressionModelParameters&gt;, LinearRegressionModelParameters&gt;" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.StandardTrainers</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Trainers.SdcaTrainerBase&lt;Microsoft.ML.Trainers.SdcaRegressionTrainer+Options,Microsoft.ML.Data.RegressionPredictionTransformer&lt;Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;,Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;</BaseTypeName>
    <BaseTypeArguments>
      <BaseTypeArgument TypeParamName="TOptions">Microsoft.ML.Trainers.SdcaRegressionTrainer+Options</BaseTypeArgument>
      <BaseTypeArgument TypeParamName="TTransformer">Microsoft.ML.Data.RegressionPredictionTransformer&lt;Microsoft.ML.Trainers.LinearRegressionModelParameters&gt;</BaseTypeArgument>
      <BaseTypeArgument TypeParamName="TModel">Microsoft.ML.Trainers.LinearRegressionModelParameters</BaseTypeArgument>
    </BaseTypeArguments>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
            The <see cref="T:Microsoft.ML.IEstimator`1" /> for training a regression model using the stochastic dual coordinate ascent method.
            </summary>
    <remarks>
        This trainer is based on the Stochastic Dual Coordinate Ascent (SDCA) method, a state-of-the-art optimization technique for convex objective functions.
        The algorithm can be scaled for use on large out-of-memory data sets due to a semi-asynchronized implementation that supports multi-threading.
        <para>
          Convergence is underwritten by periodically enforcing synchronization between primal and dual updates in a separate thread.
          Several choices of loss functions are also provided.
          The SDCA method combines several of the best properties and capabilities of logistic regression and SVM algorithms.
        </para><para>
          Note that SDCA is a stochastic and streaming optimization algorithm.
          The results depends on the order of the training data. For reproducible results, it is recommended that one sets 'Shuffle' to
          False and 'NumThreads' to 1.
          Elastic net regularization can be specified by the 'L2Const' and 'L1Threshold' parameters. Note that the 'L2Const' has an effect on the rate of convergence.
          In general, the larger the 'L2Const', the faster SDCA converges.
        </para><para>For more information, see:</para><list type="bullet"><item><description><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/main-3.pdf">Scaling Up Stochastic Dual Coordinate Ascent</a>.
          </description></item><item><description><a href="http://www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf">Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization</a>.
          </description></item></list></remarks>
  </Docs>
  <Members />
</Type>