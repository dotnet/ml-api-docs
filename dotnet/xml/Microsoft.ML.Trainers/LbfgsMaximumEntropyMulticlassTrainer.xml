<Type Name="LbfgsMaximumEntropyMulticlassTrainer" FullName="Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer">
  <TypeSignature Language="C#" Value="public sealed class LbfgsMaximumEntropyMulticlassTrainer : Microsoft.ML.Trainers.LbfgsTrainerBase&lt;Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer.Options,Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;,Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit LbfgsMaximumEntropyMulticlassTrainer extends Microsoft.ML.Trainers.LbfgsTrainerBase`3&lt;class Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer/Options, class Microsoft.ML.Data.MulticlassPredictionTransformer`1&lt;class Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;, class Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class LbfgsMaximumEntropyMulticlassTrainer&#xA;Inherits LbfgsTrainerBase(Of LbfgsMaximumEntropyMulticlassTrainer.Options, MulticlassPredictionTransformer(Of MaximumEntropyModelParameters), MaximumEntropyModelParameters)" />
  <TypeSignature Language="F#" Value="type LbfgsMaximumEntropyMulticlassTrainer = class&#xA;    inherit LbfgsTrainerBase&lt;LbfgsMaximumEntropyMulticlassTrainer.Options, MulticlassPredictionTransformer&lt;MaximumEntropyModelParameters&gt;, MaximumEntropyModelParameters&gt;" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.StandardTrainers</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Trainers.LbfgsTrainerBase&lt;Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer+Options,Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;,Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;</BaseTypeName>
    <BaseTypeArguments>
      <BaseTypeArgument TypeParamName="TOptions">Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer+Options</BaseTypeArgument>
      <BaseTypeArgument TypeParamName="TTransformer">Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;</BaseTypeArgument>
      <BaseTypeArgument TypeParamName="TModel">Microsoft.ML.Trainers.MaximumEntropyModelParameters</BaseTypeArgument>
    </BaseTypeArguments>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
        Logistic Regression is a method in statistics used to predict the probability of occurrence of an event and can be used as 
        a classification algorithm. The algorithm predicts the probability of occurrence of an event by fitting data to a logistical function.
      </summary>
    <remarks>
        If the dependent variable has more than two possible values (blood type given diagnostic test results), 
        then the logistic regression is multinomial.
        <para>
          The optimization technique used for LogisticRegression Classifier is based on the limited memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS).
          Both the L-BFGS and regular BFGS algorithms use quasi-Newtonian methods to estimate the computationally intensive 
          Hessian matrix in the equation used by Newton's method to calculate steps.
          But the L-BFGS approximation uses only a limited amount of memory to compute the next step direction,
          so that it is especially suited for problems with a large number of variables.
          The MemorySize argument specifies the number of past positions and gradients to store for use in the 
          computation of the next step.
        </para><para>
          This learner can use elastic net regularization: a linear combination of L1 (LASSO) and L2 (ridge) regularizations.
          Regularization is a method that can render an ill-posed problem more tractable by imposing constraints that provide information 
          to supplement the data and that prevents overfitting by penalizing models with extreme coefficient values.
          This can improve the generalization of the model learned by selecting the optimal complexity in the bias-variance tradeoff.
          Regularization works by adding the penalty that is associated with coefficient values to the error of the hypothesis.
          An accurate model with extreme coefficient values would be penalized more, but a less accurate model with more conservative 
          values would be penalized less. L1 and L2 regularization have different effects and uses that are complementary in certain respects.
        </para><list type="bullet"><item><description>
              L1Weight can be applied to sparse models, when working with high-dimensional data. It pulls small weights associated features
              that are relatively unimportant towards 0.
              L1 regularization is an implementation of OWLQN, based on:
              <a href="https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.68.5260">Scalable training of L1-regularized log-linear models</a></description></item><item><description>L2Weight is preferable for data that is not sparse. It pulls large weights towards zero.</description></item></list>
          Adding the ridge penalty to the regularization overcomes some of lasso's limitations. It can improve its predictive accuracy, for example, when the number of predictors is greater than the sample size. If x = l1_weight and y = l2_weight, ax + by = c defines the linear span of the regularization terms.
          The default values of x and y are both 1.
          An agressive regularization can harm predictive capacity by excluding important variables out of the model. So choosing the optimal values for the regularization parameters is important for the performance of the logistic regression model.
        <para>For more information see:</para><list type="bullet"><item><description><a href="https://research.microsoft.com/apps/pubs/default.aspx?id=78900">Scalable Training of L1-Regularized Log-Linear Models</a>.</description></item><item><description><a href="https://msdn.microsoft.com/en-us/magazine/dn904675.aspx">Test Run - L1 and L2 Regularization for Machine Learning</a>.</description></item><item><description><a href="https://en.wikipedia.org/wiki/L-BFGS">Wikipedia: L-BFGS</a>.</description></item><item><description><a href="https://en.wikipedia.org/wiki/Logistic_regression">Wikipedia: Logistic regression</a>.</description></item></list></remarks>
    <!-- No matching elements were found for the following include tag -->
    <include file="doc.xml" path="docs/members/example[@name=&quot;LogisticRegressionClassifier&quot;]/*" />
  </Docs>
  <Members>
    <Member MemberName="Fit">
      <MemberSignature Language="C#" Value="public Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt; Fit (Microsoft.ML.IDataView trainData, Microsoft.ML.Trainers.MaximumEntropyModelParameters modelParameters);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class Microsoft.ML.Data.MulticlassPredictionTransformer`1&lt;class Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt; Fit(class Microsoft.ML.IDataView trainData, class Microsoft.ML.Trainers.MaximumEntropyModelParameters modelParameters) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer.Fit(Microsoft.ML.IDataView,Microsoft.ML.Trainers.MaximumEntropyModelParameters)" />
      <MemberSignature Language="VB.NET" Value="Public Function Fit (trainData As IDataView, modelParameters As MaximumEntropyModelParameters) As MulticlassPredictionTransformer(Of MaximumEntropyModelParameters)" />
      <MemberSignature Language="F#" Value="override this.Fit : Microsoft.ML.IDataView * Microsoft.ML.Trainers.MaximumEntropyModelParameters -&gt; Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;" Usage="lbfgsMaximumEntropyMulticlassTrainer.Fit (trainData, modelParameters)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.StandardTrainers</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Data.MulticlassPredictionTransformer&lt;Microsoft.ML.Trainers.MaximumEntropyModelParameters&gt;</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="trainData" Type="Microsoft.ML.IDataView" />
        <Parameter Name="modelParameters" Type="Microsoft.ML.Trainers.MaximumEntropyModelParameters" />
      </Parameters>
      <Docs>
        <param name="trainData">To be added.</param>
        <param name="modelParameters">To be added.</param>
        <summary>
            Continues the training of a <see cref="T:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer" /> using an already trained <paramref name="modelParameters" /> and returns
            a <see cref="T:Microsoft.ML.Data.MulticlassPredictionTransformer`1" />.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>