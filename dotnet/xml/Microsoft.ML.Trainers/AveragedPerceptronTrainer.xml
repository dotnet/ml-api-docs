<Type Name="AveragedPerceptronTrainer" FullName="Microsoft.ML.Trainers.AveragedPerceptronTrainer">
  <TypeSignature Language="C#" Value="public sealed class AveragedPerceptronTrainer : Microsoft.ML.Trainers.AveragedLinearTrainer&lt;Microsoft.ML.Data.BinaryPredictionTransformer&lt;Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;,Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit AveragedPerceptronTrainer extends Microsoft.ML.Trainers.AveragedLinearTrainer`2&lt;class Microsoft.ML.Data.BinaryPredictionTransformer`1&lt;class Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;, class Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Trainers.AveragedPerceptronTrainer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class AveragedPerceptronTrainer&#xA;Inherits AveragedLinearTrainer(Of BinaryPredictionTransformer(Of LinearBinaryModelParameters), LinearBinaryModelParameters)" />
  <TypeSignature Language="F#" Value="type AveragedPerceptronTrainer = class&#xA;    inherit AveragedLinearTrainer&lt;BinaryPredictionTransformer&lt;LinearBinaryModelParameters&gt;, LinearBinaryModelParameters&gt;" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.StandardTrainers</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Trainers.AveragedLinearTrainer&lt;Microsoft.ML.Data.BinaryPredictionTransformer&lt;Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;,Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;</BaseTypeName>
    <BaseTypeArguments>
      <BaseTypeArgument TypeParamName="TTransformer">Microsoft.ML.Data.BinaryPredictionTransformer&lt;Microsoft.ML.Trainers.LinearBinaryModelParameters&gt;</BaseTypeArgument>
      <BaseTypeArgument TypeParamName="TModel">Microsoft.ML.Trainers.LinearBinaryModelParameters</BaseTypeArgument>
    </BaseTypeArguments>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
             The <see cref="T:Microsoft.ML.IEstimator`1" /> to predict a target using a linear binary classification model trained with the averaged perceptron.
             </summary>
    <remarks>
<format type="text/markdown"><![CDATA[
To create this trainer, use [AveragedPerceptron](xref:Microsoft.ML.StandardTrainersCatalog.AveragedPerceptron(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,System.String,System.String,Microsoft.ML.Trainers.IClassificationLoss,System.Single,System.Boolean,System.Single,System.Int32))
or [AveragedPerceptron(Options)](xref:Microsoft.ML.StandardTrainersCatalog.AveragedPerceptron(Microsoft.ML.BinaryClassificationCatalog.BinaryClassificationTrainers,Microsoft.ML.Trainers.AveragedPerceptronTrainer.Options)).

### Input and Output Columns
The label column data must be <xref:System.Single>. This trainer outputs the following columns:

| Column Name | Column Type | Description|
| -- | -- | -- |
| `Score` | <xref:System.Single> | The unbounded score that was calculated by the trainer to determine the prediction.|
| `PredictedLabel` | <xref:System.Boolean> | The label predicted by the trainer. `false` maps to negative score and   `true` maps to positive score.|
| `Probability` | <xref:System.Single> | The probability of the score in range [0, 1].|

### Trainer FAQ
| Question | Answer |
| -- | -- |
| Machine learning task | Binary classification |
| Is normalization required? | Yes |
| Is caching required? | No |
| Is convertible to ONNX format? | Yes |
| Additional required NuGet | None |

### Training Algorithm Details
The perceptron is a classification algorithm that makes its predictions by finding a separating hyperplane.
For instance, with feature values f0, f1,..., f_D-1, the prediction is given by determining what side of the hyperplane the point falls into.
That is the same as the sign of sigma[0, D-1] (w_i * f_i), where w_0, w_1,..., w_D-1 are the weights computed by the algorithm.

The perceptron is an online algorithm, which means it processes the instances in the training set one at a time.
It starts with a set of initial weights (zero, random, or initialized from a previous learner). Then, for each example in the training set, the weighted sum of the features (sigma[0, D-1] (w_i * f_i)) is computed.
If this value has the same sign as the label of the current example, the weights remain the same. If they have opposite signs,
the weights vector is updated by either adding or subtracting (if the label is positive or negative, respectively) the feature vector of the current example,
multiplied by a factor 0 &lt; a &lt;= 1, called the learning rate. In a generalization of this algorithm, the weights are updated by adding the feature vector multiplied by the learning rate,
and by the gradient of some loss function (in the specific case described above, the loss is hinge-loss, whose gradient is 1 when it is non-zero).

In Averaged Perceptron (aka voted-perceptron), for each iteration, i.e. pass through the training data, a weight vector is calculated as explained above.
The final prediction is then calculate by averaging the weighted sum from each weight vector and looking at the sign of the result.

For more information see [Wikipedia entry for Perceptron](https://en.wikipedia.org/wiki/Perceptron)
or [Large Margin Classification Using the Perceptron Algorithm](https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.8200).
]]>
</format>

 </remarks>
			 </Docs>
  <Members />
</Type>