<Type Name="OnnxScoringEstimator" FullName="Microsoft.ML.Transforms.Onnx.OnnxScoringEstimator">
  <TypeSignature Language="C#" Value="public sealed class OnnxScoringEstimator : Microsoft.ML.Data.TrivialEstimator&lt;Microsoft.ML.Transforms.Onnx.OnnxTransformer&gt;" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit OnnxScoringEstimator extends Microsoft.ML.Data.TrivialEstimator`1&lt;class Microsoft.ML.Transforms.Onnx.OnnxTransformer&gt;" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Transforms.Onnx.OnnxScoringEstimator" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class OnnxScoringEstimator&#xA;Inherits TrivialEstimator(Of OnnxTransformer)" />
  <TypeSignature Language="F#" Value="type OnnxScoringEstimator = class&#xA;    inherit TrivialEstimator&lt;OnnxTransformer&gt;" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.OnnxTransformer</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Data.TrivialEstimator&lt;Microsoft.ML.Transforms.Onnx.OnnxTransformer&gt;</BaseTypeName>
    <BaseTypeArguments>
      <BaseTypeArgument TypeParamName="!0">Microsoft.ML.Transforms.Onnx.OnnxTransformer</BaseTypeArgument>
    </BaseTypeArguments>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
      <see cref="T:Microsoft.ML.IEstimator`1" /> for scoring ONNX models in the ML.NET framework.
             </summary>
    <remarks>
      <format type="text/markdown"><![CDATA[
            
             ###  Estimator Characteristics
             |  |  |
             | -- | -- |
             | Does this estimator need to look at the data to train its parameters? | No |
             | Input column data type | Known-sized vector of <xref:System.Single> or <xref:System.Double> types |
             | Output column data type | As specified by the ONNX model |
             | Required NuGet in addition to Microsoft.ML | Microsoft.ML.OnnxTransformer (always),  either Microsoft.ML.OnnxRuntime 1.3.0 (for CPU processing) or Microsoft.ML.OnnxRuntime.Gpu 1.3.0 (for GPU processing if GPU is available) |
             | Exportable to ONNX | No |
            
             To create this estimator use the following APIs:
             [ApplyOnnxModel](xref:Microsoft.ML.OnnxCatalog.ApplyOnnxModel*)
            
             Supports inferencing of models in ONNX 1.6 format (opset 11), using the [Microsoft.ML.OnnxRuntime](https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime/) library.
             Models are scored on CPU if the project references Microsoft.ML.OnnxRuntime and on the GPU if the project references Microsoft.ML.OnnxRuntime.Gpu.
             Every project using the OnnxScoringEstimator must reference one of the above two packages.
            
             To run on a GPU, use the
             NuGet package [Microsoft.ML.OnnxRuntime.Gpu](https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.Gpu/) instead of the Microsoft.ML.OnnxRuntime nuget (which is for CPU processing). Microsoft.ML.OnnxRuntime.Gpu
             requires a [CUDA supported GPU](https://developer.nvidia.com/cuda-gpus#compute), the [CUDA 10.1 Toolkit](https://developer.nvidia.com/cuda-downloads), and [cuDNN 7.6.5](https://developer.nvidia.com/cudnn) (as indicated on [Onnxruntime's documentation](https://github.com/Microsoft/onnxruntime#default-gpu-cuda)).
             When creating the estimator through [ApplyOnnxModel](xref:Microsoft.ML.OnnxCatalog.ApplyOnnxModel*), set the parameter 'gpuDeviceId' to a valid non-negative integer. Typical device ID values are 0 or 1. If the GPU device isn't found but 'fallbackToCpu = true' then the estimator will run on the CPU. If the GPU device isn't found but 'fallbackToCpu = false' then the estimator will throw an exception
            
             The inputs and outputs of the ONNX models must be Tensor type. Sequence and Maps are not yet supported.
            
             Internally, OnnxTransformer (the return value of OnnxScoringEstimator.Fit()) holds a reference to an inference session which points to unmanaged memory owned by OnnxRuntime.dll.
             Whenever there is a call to [ApplyOnnxModel](xref:Microsoft.ML.OnnxCatalog.ApplyOnnxModel*) in a pipeline, it is advised to cast the return value of the Fit() call to IDisposable and call Dispose() to ensure that there are no memory leaks.
            
             OnnxRuntime works on Windows, MacOS and Ubuntu 16.04 Linux 64-bit platforms.
             Visit [ONNX Models](https://github.com/onnx/models) to see a list of readily available models to get started with.
             Refer to [ONNX](http://onnx.ai) for more information.
            
             ]]></format>
    </remarks>
  </Docs>
  <Members>
    <Member MemberName="GetOutputSchema">
      <MemberSignature Language="C#" Value="public override Microsoft.ML.SchemaShape GetOutputSchema (Microsoft.ML.SchemaShape inputSchema);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig virtual instance class Microsoft.ML.SchemaShape GetOutputSchema(class Microsoft.ML.SchemaShape inputSchema) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Transforms.Onnx.OnnxScoringEstimator.GetOutputSchema(Microsoft.ML.SchemaShape)" />
      <MemberSignature Language="VB.NET" Value="Public Overrides Function GetOutputSchema (inputSchema As SchemaShape) As SchemaShape" />
      <MemberSignature Language="F#" Value="override this.GetOutputSchema : Microsoft.ML.SchemaShape -&gt; Microsoft.ML.SchemaShape" Usage="onnxScoringEstimator.GetOutputSchema inputSchema" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.OnnxTransformer</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.ML.SchemaShape</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputSchema" Type="Microsoft.ML.SchemaShape" />
      </Parameters>
      <Docs>
        <param name="inputSchema">To be added.</param>
        <summary>
            Returns the <see cref="T:Microsoft.ML.SchemaShape" /> of the schema which will be produced by the transformer.
            Used for schema propagation and verification in a pipeline.
            </summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
