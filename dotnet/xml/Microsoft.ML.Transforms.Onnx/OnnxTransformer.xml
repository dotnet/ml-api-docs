<Type Name="OnnxTransformer" FullName="Microsoft.ML.Transforms.Onnx.OnnxTransformer">
  <TypeSignature Language="C#" Value="public sealed class OnnxTransformer : Microsoft.ML.Data.RowToRowTransformerBase" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit OnnxTransformer extends Microsoft.ML.Data.RowToRowTransformerBase" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Transforms.Onnx.OnnxTransformer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class OnnxTransformer&#xA;Inherits RowToRowTransformerBase" />
  <TypeSignature Language="F#" Value="type OnnxTransformer = class&#xA;    inherit RowToRowTransformerBase" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.OnnxTransformer</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Data.RowToRowTransformerBase</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
      <p>A transform for scoring ONNX models in the ML.NET framework.</p>
      <format type="text/markdown"><![CDATA[
            [!code-csharp[MF](~/../docs/samples/docs/samples/Microsoft.ML.Samples/Dynamic/OnnxTransform.cs)]
            ]]></format>
    </summary>
    <remarks>
      <p>Supports inferencing of models in ONNX 1.2 and 1.3 format (opset 7, 8 and 9), using the
            <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime/">Microsoft.ML.OnnxRuntime</a> library.
            </p>
      <p>Models are scored on CPU by default. If GPU execution is needed (optional), use the
            NuGet package available at
            <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.Gpu/">Microsoft.ML.OnnxRuntime.Gpu</a>
            and download
            <a href="https://developer.nvidia.com/cuda-downloads">CUDA 9.1 Toolkit</a>
            and
            <a href="https://developer.nvidia.com/cudnn">cuDNN</a>.
             Set parameter 'gpuDeviceId' to a valid non-negative integer. Typical device ID values are 0 or 1.
            </p>
      <p>The inputs and outputs of the ONNX models must be Tensor type. Sequence and Maps are not yet supported.</p>
      <p>OnnxRuntime currently works on Windows and Ubuntu 16.04 Linux 64-bit platforms. Mac OS to be supported soon.</p>
      <p>Visit https://github.com/onnx/models to see a list of readily available models to get started with.</p>
      <p>Refer to http://onnx.ai' for more information about ONNX.</p>
    </remarks>
  </Docs>
  <Members />
</Type>