<Type Name="LlamaTokenizer" FullName="Microsoft.ML.Tokenizers.LlamaTokenizer">
  <TypeSignature Language="C#" Value="public sealed class LlamaTokenizer : Microsoft.ML.Tokenizers.SentencePieceTokenizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit LlamaTokenizer extends Microsoft.ML.Tokenizers.SentencePieceTokenizer" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Tokenizers.LlamaTokenizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class LlamaTokenizer&#xA;Inherits SentencePieceTokenizer" />
  <TypeSignature Language="F#" Value="type LlamaTokenizer = class&#xA;    inherit SentencePieceTokenizer" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.Tokenizers</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Tokenizers.SentencePieceTokenizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
            LlamaTokenizer is SentencePieceTokenizer which is implemented based on https://github.com/google/sentencepiece.
            </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="Create">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Tokenizers.LlamaTokenizer Create (System.IO.Stream modelStream, bool addBeginOfSentence = true, bool addEndOfSentence = false, System.Collections.Generic.IReadOnlyDictionary&lt;string,int&gt;? specialTokens = default);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Tokenizers.LlamaTokenizer Create(class System.IO.Stream modelStream, bool addBeginOfSentence, bool addEndOfSentence, class System.Collections.Generic.IReadOnlyDictionary`2&lt;string, int32&gt; specialTokens) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Tokenizers.LlamaTokenizer.Create(System.IO.Stream,System.Boolean,System.Boolean,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function Create (modelStream As Stream, Optional addBeginOfSentence As Boolean = true, Optional addEndOfSentence As Boolean = false, Optional specialTokens As IReadOnlyDictionary(Of String, Integer) = Nothing) As LlamaTokenizer" />
      <MemberSignature Language="F#" Value="static member Create : System.IO.Stream * bool * bool * System.Collections.Generic.IReadOnlyDictionary&lt;string, int&gt; -&gt; Microsoft.ML.Tokenizers.LlamaTokenizer" Usage="Microsoft.ML.Tokenizers.LlamaTokenizer.Create (modelStream, addBeginOfSentence, addEndOfSentence, specialTokens)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.Tokenizers</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Tokenizers.LlamaTokenizer</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="modelStream" Type="System.IO.Stream" />
        <Parameter Name="addBeginOfSentence" Type="System.Boolean" />
        <Parameter Name="addEndOfSentence" Type="System.Boolean" />
        <Parameter Name="specialTokens" Type="System.Collections.Generic.IReadOnlyDictionary&lt;System.String,System.Int32&gt;" />
      </Parameters>
      <Docs>
        <param name="modelStream">The stream containing the SentencePiece Bpe model.</param>
        <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
        <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
        <param name="specialTokens">The additional tokens to add to the vocabulary.</param>
        <summary>
            Create from the given model stream a LlamaTokenizer which is based on SentencePieceTokenizer. The model stream should contain the SentencePiece Bpe model according to
            https://github.com/google/sentencepiece/blob/master/src/sentencepiece_model.proto specification.
            </summary>
        <returns>To be added.</returns>
        <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
