<Type Name="Phi2Tokenizer" FullName="Microsoft.ML.Tokenizers.Phi2Tokenizer">
  <TypeSignature Language="C#" Value="public sealed class Phi2Tokenizer : Microsoft.ML.Tokenizers.CodeGenTokenizer" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit Phi2Tokenizer extends Microsoft.ML.Tokenizers.CodeGenTokenizer" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Tokenizers.Phi2Tokenizer" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class Phi2Tokenizer&#xA;Inherits CodeGenTokenizer" />
  <TypeSignature Language="F#" Value="type Phi2Tokenizer = class&#xA;    inherit CodeGenTokenizer" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.Tokenizers</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.ML.Tokenizers.CodeGenTokenizer</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
            Represent the Byte Pair Encoding model.
            Implement the Phi2 tokenizer described in https://huggingface.co/microsoft/phi-2
            </summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="Create">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Tokenizers.Phi2Tokenizer Create (System.IO.Stream vocabStream, System.IO.Stream mergesStream, bool addPrefixSpace = false, bool addBeginOfSentence = false, bool addEndOfSentence = false);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Tokenizers.Phi2Tokenizer Create(class System.IO.Stream vocabStream, class System.IO.Stream mergesStream, bool addPrefixSpace, bool addBeginOfSentence, bool addEndOfSentence) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Tokenizers.Phi2Tokenizer.Create(System.IO.Stream,System.IO.Stream,System.Boolean,System.Boolean,System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function Create (vocabStream As Stream, mergesStream As Stream, Optional addPrefixSpace As Boolean = false, Optional addBeginOfSentence As Boolean = false, Optional addEndOfSentence As Boolean = false) As Phi2Tokenizer" />
      <MemberSignature Language="F#" Value="static member Create : System.IO.Stream * System.IO.Stream * bool * bool * bool -&gt; Microsoft.ML.Tokenizers.Phi2Tokenizer" Usage="Microsoft.ML.Tokenizers.Phi2Tokenizer.Create (vocabStream, mergesStream, addPrefixSpace, addBeginOfSentence, addEndOfSentence)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.Tokenizers</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Tokenizers.Phi2Tokenizer</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="vocabStream" Type="System.IO.Stream" />
        <Parameter Name="mergesStream" Type="System.IO.Stream" />
        <Parameter Name="addPrefixSpace" Type="System.Boolean" />
        <Parameter Name="addBeginOfSentence" Type="System.Boolean" />
        <Parameter Name="addEndOfSentence" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="vocabStream">The stream containing the vocab file.</param>
        <param name="mergesStream">The stream containing the merges file.</param>
        <param name="addPrefixSpace">Indicate whether to add a space before the token.</param>
        <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
        <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
        <summary>
            Create a CodeGen Phi2 tokenizer from the given vocab and merges streams.
            </summary>
        <returns>The CodeGen tokenizer object.</returns>
        <remarks>
            The tokenizer will be created according to the configuration specified in https://huggingface.co/microsoft/phi-2/raw/main/tokenizer.json.
            It is important to provide the similar vocab and merges files to the ones used in the training of the model.
            The vocab and merges files can be downloaded from the following links:
                https://huggingface.co/microsoft/phi-2/resolve/main/vocab.json?download=true
                https://huggingface.co/microsoft/phi-2/resolve/main/merges.txt?download=true
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
      </Docs>
    </Member>
  </Members>
</Type>
