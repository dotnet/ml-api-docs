<Type Name="FastTree" FullName="Microsoft.ML.Runtime.FastTree.FastTree">
  <TypeSignature Language="C#" Value="public static class FastTree" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi abstract sealed beforefieldinit FastTree extends System.Object" />
  <TypeSignature Language="DocId" Value="T:Microsoft.ML.Runtime.FastTree.FastTree" />
  <TypeSignature Language="VB.NET" Value="Public Class FastTree" />
  <TypeSignature Language="F#" Value="type FastTree = class" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.ML.FastTree</AssemblyName>
    <AssemblyVersion>1.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>To be added.</summary>
    <remarks>To be added.</remarks>
  </Docs>
  <Members>
    <Member MemberName="TrainBinary">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Runtime.EntryPoints.CommonOutputs.BinaryClassificationOutput TrainBinary (Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.FastTree.FastTreeBinaryClassificationTrainer.Arguments input);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Runtime.EntryPoints.CommonOutputs/BinaryClassificationOutput TrainBinary(class Microsoft.ML.Runtime.IHostEnvironment env, class Microsoft.ML.Runtime.FastTree.FastTreeBinaryClassificationTrainer/Arguments input) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Runtime.FastTree.FastTree.TrainBinary(Microsoft.ML.Runtime.IHostEnvironment,Microsoft.ML.Runtime.FastTree.FastTreeBinaryClassificationTrainer.Arguments)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TrainBinary (env As IHostEnvironment, input As FastTreeBinaryClassificationTrainer.Arguments) As CommonOutputs.BinaryClassificationOutput" />
      <MemberSignature Language="F#" Value="static member TrainBinary : Microsoft.ML.Runtime.IHostEnvironment * Microsoft.ML.Runtime.FastTree.FastTreeBinaryClassificationTrainer.Arguments -&gt; Microsoft.ML.Runtime.EntryPoints.CommonOutputs.BinaryClassificationOutput" Usage="Microsoft.ML.Runtime.FastTree.FastTree.TrainBinary (env, input)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.FastTree</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Microsoft.ML.Runtime.EntryPoints.TlcModule/EntryPoint(Desc="Uses a logit-boost boosted tree learner to perform binary classification.", Name="Trainers.FastTreeBinaryClassifier", Remarks="&lt;remarks&gt;\r\n&lt;para&gt;FastTrees is an efficient implementation of the &lt;a href='https://arxiv.org/abs/1505.01866'&gt;MART&lt;/a&gt; gradient boosting algorithm. \r\nGradient boosting is a machine learning technique for regression problems. \r\nIt builds each regression tree in a step-wise fashion, using a predefined loss function to measure the error for each step and corrects for it in the next. \r\nSo this prediction model is actually an ensemble of weaker prediction models. In regression problems, boosting builds a series of of such trees in a step-wise fashion and then selects the optimal tree using an arbitrary differentiable loss function.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nMART learns an ensemble of regression trees, which is a decision tree with scalar values in its leaves. \r\nA decision (or regression) tree is a binary tree-like flow chart, where at each interior node one decides which of the two child nodes to continue to based on one of the feature values from the input. \r\nAt each leaf node, a value is returned. In the interior nodes, the decision is based on the test 'x &lt;= v' where x is the value of the feature in the input sample and v is one of the possible values of this feature. \r\nThe functions that can be produced by a regression tree are all the piece-wise constant functions.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nThe ensemble of trees is produced by computing, in each step, a regression tree that approximates the gradient of the loss function, and adding it to the previous tree with coefficients that minimize the loss of the new tree.\r\nThe output of the ensemble produced by MART on a given instance is the sum of the tree outputs.\r\n&lt;/para&gt;\r\n&lt;list type='bullet'&gt;\r\n&lt;item&gt;In case of a binary classification problem, the output is converted to a probability by using some form of calibration.&lt;/item&gt;\r\n&lt;item&gt;In case of a regression problem, the output is the predicted value of the function.&lt;/item&gt;\r\n&lt;item&gt;In case of a ranking problem, the instances are ordered by the output value of the ensemble.&lt;/item&gt;\r\n&lt;/list&gt;\r\n&lt;a href='https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting'&gt;Wikipedia: Gradient boosting (Gradient tree boosting)&lt;/a&gt;.\r\n&lt;a href='http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aos/1013203451'&gt;Greedy function approximation: A gradient boosting machine.&lt;/a&gt;.\r\n&lt;/remarks&gt;", ShortName="ftc", UserName="FastTree (Boosted Trees) Classification")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Runtime.EntryPoints.CommonOutputs+BinaryClassificationOutput</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="env" Type="Microsoft.ML.Runtime.IHostEnvironment" />
        <Parameter Name="input" Type="Microsoft.ML.Runtime.FastTree.FastTreeBinaryClassificationTrainer+Arguments" />
      </Parameters>
      <Docs>
        <param name="env">To be added.</param>
        <param name="input">To be added.</param>
        <summary>To be added.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TrainRanking">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RankingOutput TrainRanking (Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.Arguments input);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Runtime.EntryPoints.CommonOutputs/RankingOutput TrainRanking(class Microsoft.ML.Runtime.IHostEnvironment env, class Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer/Arguments input) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Runtime.FastTree.FastTree.TrainRanking(Microsoft.ML.Runtime.IHostEnvironment,Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.Arguments)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TrainRanking (env As IHostEnvironment, input As FastTreeRankingTrainer.Arguments) As CommonOutputs.RankingOutput" />
      <MemberSignature Language="F#" Value="static member TrainRanking : Microsoft.ML.Runtime.IHostEnvironment * Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer.Arguments -&gt; Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RankingOutput" Usage="Microsoft.ML.Runtime.FastTree.FastTree.TrainRanking (env, input)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.FastTree</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Microsoft.ML.Runtime.EntryPoints.TlcModule/EntryPoint(Desc="Trains gradient boosted decision trees to the LambdaRank quasi-gradient.", Name="Trainers.FastTreeRanker", Remarks="&lt;remarks&gt;\r\n&lt;para&gt;FastTrees is an efficient implementation of the &lt;a href='https://arxiv.org/abs/1505.01866'&gt;MART&lt;/a&gt; gradient boosting algorithm. \r\nGradient boosting is a machine learning technique for regression problems. \r\nIt builds each regression tree in a step-wise fashion, using a predefined loss function to measure the error for each step and corrects for it in the next. \r\nSo this prediction model is actually an ensemble of weaker prediction models. In regression problems, boosting builds a series of of such trees in a step-wise fashion and then selects the optimal tree using an arbitrary differentiable loss function.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nMART learns an ensemble of regression trees, which is a decision tree with scalar values in its leaves. \r\nA decision (or regression) tree is a binary tree-like flow chart, where at each interior node one decides which of the two child nodes to continue to based on one of the feature values from the input. \r\nAt each leaf node, a value is returned. In the interior nodes, the decision is based on the test 'x &lt;= v' where x is the value of the feature in the input sample and v is one of the possible values of this feature. \r\nThe functions that can be produced by a regression tree are all the piece-wise constant functions.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nThe ensemble of trees is produced by computing, in each step, a regression tree that approximates the gradient of the loss function, and adding it to the previous tree with coefficients that minimize the loss of the new tree.\r\nThe output of the ensemble produced by MART on a given instance is the sum of the tree outputs.\r\n&lt;/para&gt;\r\n&lt;list type='bullet'&gt;\r\n&lt;item&gt;In case of a binary classification problem, the output is converted to a probability by using some form of calibration.&lt;/item&gt;\r\n&lt;item&gt;In case of a regression problem, the output is the predicted value of the function.&lt;/item&gt;\r\n&lt;item&gt;In case of a ranking problem, the instances are ordered by the output value of the ensemble.&lt;/item&gt;\r\n&lt;/list&gt;\r\n&lt;a href='https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting'&gt;Wikipedia: Gradient boosting (Gradient tree boosting)&lt;/a&gt;.\r\n&lt;a href='http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aos/1013203451'&gt;Greedy function approximation: A gradient boosting machine.&lt;/a&gt;.\r\n&lt;/remarks&gt;", ShortName="ftrank", UserName="FastTree (Boosted Trees) Ranking")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Runtime.EntryPoints.CommonOutputs+RankingOutput</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="env" Type="Microsoft.ML.Runtime.IHostEnvironment" />
        <Parameter Name="input" Type="Microsoft.ML.Runtime.FastTree.FastTreeRankingTrainer+Arguments" />
      </Parameters>
      <Docs>
        <param name="env">To be added.</param>
        <param name="input">To be added.</param>
        <summary>To be added.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TrainRegression">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RegressionOutput TrainRegression (Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer.Arguments input);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Runtime.EntryPoints.CommonOutputs/RegressionOutput TrainRegression(class Microsoft.ML.Runtime.IHostEnvironment env, class Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer/Arguments input) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Runtime.FastTree.FastTree.TrainRegression(Microsoft.ML.Runtime.IHostEnvironment,Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer.Arguments)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TrainRegression (env As IHostEnvironment, input As FastTreeRegressionTrainer.Arguments) As CommonOutputs.RegressionOutput" />
      <MemberSignature Language="F#" Value="static member TrainRegression : Microsoft.ML.Runtime.IHostEnvironment * Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer.Arguments -&gt; Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RegressionOutput" Usage="Microsoft.ML.Runtime.FastTree.FastTree.TrainRegression (env, input)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.FastTree</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Microsoft.ML.Runtime.EntryPoints.TlcModule/EntryPoint(Desc="Trains gradient boosted decision trees to fit target values using least-squares.", Name="Trainers.FastTreeRegressor", Remarks="&lt;remarks&gt;\r\n&lt;para&gt;FastTrees is an efficient implementation of the &lt;a href='https://arxiv.org/abs/1505.01866'&gt;MART&lt;/a&gt; gradient boosting algorithm. \r\nGradient boosting is a machine learning technique for regression problems. \r\nIt builds each regression tree in a step-wise fashion, using a predefined loss function to measure the error for each step and corrects for it in the next. \r\nSo this prediction model is actually an ensemble of weaker prediction models. In regression problems, boosting builds a series of of such trees in a step-wise fashion and then selects the optimal tree using an arbitrary differentiable loss function.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nMART learns an ensemble of regression trees, which is a decision tree with scalar values in its leaves. \r\nA decision (or regression) tree is a binary tree-like flow chart, where at each interior node one decides which of the two child nodes to continue to based on one of the feature values from the input. \r\nAt each leaf node, a value is returned. In the interior nodes, the decision is based on the test 'x &lt;= v' where x is the value of the feature in the input sample and v is one of the possible values of this feature. \r\nThe functions that can be produced by a regression tree are all the piece-wise constant functions.\r\n&lt;/para&gt;\r\n&lt;para&gt;\r\nThe ensemble of trees is produced by computing, in each step, a regression tree that approximates the gradient of the loss function, and adding it to the previous tree with coefficients that minimize the loss of the new tree.\r\nThe output of the ensemble produced by MART on a given instance is the sum of the tree outputs.\r\n&lt;/para&gt;\r\n&lt;list type='bullet'&gt;\r\n&lt;item&gt;In case of a binary classification problem, the output is converted to a probability by using some form of calibration.&lt;/item&gt;\r\n&lt;item&gt;In case of a regression problem, the output is the predicted value of the function.&lt;/item&gt;\r\n&lt;item&gt;In case of a ranking problem, the instances are ordered by the output value of the ensemble.&lt;/item&gt;\r\n&lt;/list&gt;\r\n&lt;a href='https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting'&gt;Wikipedia: Gradient boosting (Gradient tree boosting)&lt;/a&gt;.\r\n&lt;a href='http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aos/1013203451'&gt;Greedy function approximation: A gradient boosting machine.&lt;/a&gt;.\r\n&lt;/remarks&gt;", ShortName="ftr", UserName="FastTree (Boosted Trees) Regression")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Runtime.EntryPoints.CommonOutputs+RegressionOutput</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="env" Type="Microsoft.ML.Runtime.IHostEnvironment" />
        <Parameter Name="input" Type="Microsoft.ML.Runtime.FastTree.FastTreeRegressionTrainer+Arguments" />
      </Parameters>
      <Docs>
        <param name="env">To be added.</param>
        <param name="input">To be added.</param>
        <summary>To be added.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="TrainTweedieRegression">
      <MemberSignature Language="C#" Value="public static Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RegressionOutput TrainTweedieRegression (Microsoft.ML.Runtime.IHostEnvironment env, Microsoft.ML.Runtime.FastTree.FastTreeTweedieTrainer.Arguments input);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig class Microsoft.ML.Runtime.EntryPoints.CommonOutputs/RegressionOutput TrainTweedieRegression(class Microsoft.ML.Runtime.IHostEnvironment env, class Microsoft.ML.Runtime.FastTree.FastTreeTweedieTrainer/Arguments input) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.ML.Runtime.FastTree.FastTree.TrainTweedieRegression(Microsoft.ML.Runtime.IHostEnvironment,Microsoft.ML.Runtime.FastTree.FastTreeTweedieTrainer.Arguments)" />
      <MemberSignature Language="VB.NET" Value="Public Shared Function TrainTweedieRegression (env As IHostEnvironment, input As FastTreeTweedieTrainer.Arguments) As CommonOutputs.RegressionOutput" />
      <MemberSignature Language="F#" Value="static member TrainTweedieRegression : Microsoft.ML.Runtime.IHostEnvironment * Microsoft.ML.Runtime.FastTree.FastTreeTweedieTrainer.Arguments -&gt; Microsoft.ML.Runtime.EntryPoints.CommonOutputs.RegressionOutput" Usage="Microsoft.ML.Runtime.FastTree.FastTree.TrainTweedieRegression (env, input)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.ML.FastTree</AssemblyName>
        <AssemblyVersion>1.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Microsoft.ML.Runtime.EntryPoints.TlcModule/EntryPoint(Desc="Trains gradient boosted decision trees to fit target values using a Tweedie loss function. This learner is a generalization of Poisson, compound Poisson, and gamma regression.", Name="Trainers.FastTreeTweedieRegressor", ShortName="fttweedie", UserName="FastTree (Boosted Trees) Tweedie Regression")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Microsoft.ML.Runtime.EntryPoints.CommonOutputs+RegressionOutput</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="env" Type="Microsoft.ML.Runtime.IHostEnvironment" />
        <Parameter Name="input" Type="Microsoft.ML.Runtime.FastTree.FastTreeTweedieTrainer+Arguments" />
      </Parameters>
      <Docs>
        <param name="env">To be added.</param>
        <param name="input">To be added.</param>
        <summary>To be added.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>